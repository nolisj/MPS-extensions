{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"table tbody tr:nth-child(1) td:nth-child(2) { color: limegreen; } table tbody tr:nth-child(2) td:nth-child(2), table tbody tr:nth-child(3) td:nth-child(2), table tbody tr:nth-child(6) td:nth-child(2) { color: orange; } table tbody tr + tr + tr + tr td:nth-child(2) { color: tomato; } Welcome to the MPS Extensions The MPS extensions aim to ease language development within MPS. They are maintained by itemis, JetBrains and the open source community and its development is closely related to the development of MPS. MPS Extensions and mbeddr (platform) How is the relationship between the mbeddr (platform) and this project? The mbeddr project in the past developed a set of extensions that where used to allow easier development of languages with MPS. These extensions where not C specific and were called mbeddr platform . This project aims to give these extensions a new home. To make them more visible but also emphasise that these extensions are independent of mbeddr and it's C implementation in MPS. The midterm goal is to migrate most of these extensions in this project. Not all of them will really fit here because some of these are very experimental or have very specific use cases. Our goal is to migrate the stable bits first. See the migration section of the documentation on what we plan to migrate at the moment and how you could help. Getting Started To get started grab a release from our release page on github . Extract the archive and point a project or global library in MPS to the location where you extracted it. See the documentation regarding the individual extensions above. The documentation is \"currently work in progress\" as it being ported over from the mbeddr platform repository. Documentation related contributions are very welcome! We are also working on providing a zip file with all the sandboxes we have in our repository in order to try things out and see how the extensions work. See this issue for details . Artefacts in the Nexus We also provide the artefacts as a maven repository. Where you can fetch them during your CI build to setup your local development environment. Maven: project ... repositories repository id itemis.mbeddr /id url https://projects.itemis.de/nexus/content/repositories/mbeddr /url /repository /repositories dependencies ... dependency groupId de.itemis.mps /groupId artifactId extensions /artifactId version 2020.2 /version type zip /type /dependency /dependencies /project Gradle: repositories { maven { url 'https://projects.itemis.de/nexus/content/repositories/mbeddr' } } configurations { mpsExtensions } dependencies { mpsExtensions de.itemis.mps:extensions:2020.2.+ } Versions The version number reflects the MPS version the extensions are compatible with. For instance 2018.1.X is compatible with MPS 2018.1, 2017.3.X is compatible with MPS 2017.3.6. We only maintain compatibility with the latest minor release for each major version. While a 2017.3.x version of the extension might work with a on older version than MPS 2017.3.6 we only test it against the latest. Current Versions Currently these MPS versions are supported. Versions prior to MPS 2017.3 might still be available as the mbeddr platform but are not maintained in the repository. A version in maintenance will not get actively new features and is only maintained with bugfixes. We are happy to accept pull request for versions in maintenance with bugfixes but active feature development only happens for the latest MPS version. MPS Version State 2020.2 active development 2020.1 maintenance 2019.3 maintenance 2019.2 not maintained 2019.1 not maintained 2018.3 maintenance 2018.2 not maintained 2018.1 not maintained 2017.3 not maintained 2017.2 not maintained 2017.1 not maintained Grammar Cells Migration Starting from version 2018.2.348 the MPS extensions also contain grammar cells which have been ported over from the mbeddr platform. For users of grammar cells this is mostly a transparent change since the mbeddr platform currently repackages the MPS extensions. This means that if you are using the mbeddr platform today you should not have to do much manual work. mbeddr changes The most obvious change here is that the version of the mbeddr artefacts was incremented by a minor. That means you will have to adjust your build files to get the version 1.1+ instead of 1.0* . Please consult the documentation of your build tool how to configure your dependency resolving. We did this change to ensure that you do not accidentally get the new version. See the last section for the reason. The 1.0+ versions remain in our nexus as they are in the current state but will not get any updates. If you want to get newer versions of the mbeddr platform your have to change your dependency version. If you download your artefacts manually from the mbeddr Github page everything is the same as before but the version number is incremented. Other than that the artefacts didn't change and still contain the repackaged platform. We are planning to add a additional artefact that doesn't repackaged the MPS-extensions in the future to allow you more flexibility. Changes to MPS Extensions In the MPS extensions we only have additive changes. We added the mpsutil.grammarcells.* modules in that same state as they were in the mbeddr platform. You shouldn't observe any changes. In addition to that we kept the language ids to avoid any visible change for existing users of the languages. The version number of the MPS extensions remain in the normal scheme as documented above. Required changes for projects If your project is using grammar cells today it is using them through the mbeddr platform. If you do so you simply need to adjust the version number the dependency on the mbeddr platform and you are good to go. I your build scripts show errors after changing the dependency a simple \"reload modules from disk\" intention should be able to fix them. In case you currently only have dependency to the mbeddr platform because you want to use grammar cells you are now able to drop that dependency. To do so replace the dependency on the mbeddr platform with a dependency on the correct version of the MPS extensions. In this case you need to modify your MPS build scripts to no longer use the mbeddr platform as dependency but the MPS extensions. Afterwards MPS will complain that it can't find the dependency on the grammar cells languages in the build. To fix this invoke the \"reload modules from disk\" on the affected build script and the errors should go away.","title":"Home"},{"location":"#welcome-to-the-mps-extensions","text":"The MPS extensions aim to ease language development within MPS. They are maintained by itemis, JetBrains and the open source community and its development is closely related to the development of MPS.","title":"Welcome to the MPS Extensions"},{"location":"#mps-extensions-and-mbeddr-platform","text":"How is the relationship between the mbeddr (platform) and this project? The mbeddr project in the past developed a set of extensions that where used to allow easier development of languages with MPS. These extensions where not C specific and were called mbeddr platform . This project aims to give these extensions a new home. To make them more visible but also emphasise that these extensions are independent of mbeddr and it's C implementation in MPS. The midterm goal is to migrate most of these extensions in this project. Not all of them will really fit here because some of these are very experimental or have very specific use cases. Our goal is to migrate the stable bits first. See the migration section of the documentation on what we plan to migrate at the moment and how you could help.","title":"MPS Extensions and mbeddr (platform)"},{"location":"#getting-started","text":"To get started grab a release from our release page on github . Extract the archive and point a project or global library in MPS to the location where you extracted it. See the documentation regarding the individual extensions above. The documentation is \"currently work in progress\" as it being ported over from the mbeddr platform repository. Documentation related contributions are very welcome! We are also working on providing a zip file with all the sandboxes we have in our repository in order to try things out and see how the extensions work. See this issue for details .","title":"Getting Started"},{"location":"#artefacts-in-the-nexus","text":"We also provide the artefacts as a maven repository. Where you can fetch them during your CI build to setup your local development environment. Maven: project ... repositories repository id itemis.mbeddr /id url https://projects.itemis.de/nexus/content/repositories/mbeddr /url /repository /repositories dependencies ... dependency groupId de.itemis.mps /groupId artifactId extensions /artifactId version 2020.2 /version type zip /type /dependency /dependencies /project Gradle: repositories { maven { url 'https://projects.itemis.de/nexus/content/repositories/mbeddr' } } configurations { mpsExtensions } dependencies { mpsExtensions de.itemis.mps:extensions:2020.2.+ }","title":"Artefacts in the Nexus"},{"location":"#versions","text":"The version number reflects the MPS version the extensions are compatible with. For instance 2018.1.X is compatible with MPS 2018.1, 2017.3.X is compatible with MPS 2017.3.6. We only maintain compatibility with the latest minor release for each major version. While a 2017.3.x version of the extension might work with a on older version than MPS 2017.3.6 we only test it against the latest.","title":"Versions"},{"location":"#current-versions","text":"Currently these MPS versions are supported. Versions prior to MPS 2017.3 might still be available as the mbeddr platform but are not maintained in the repository. A version in maintenance will not get actively new features and is only maintained with bugfixes. We are happy to accept pull request for versions in maintenance with bugfixes but active feature development only happens for the latest MPS version. MPS Version State 2020.2 active development 2020.1 maintenance 2019.3 maintenance 2019.2 not maintained 2019.1 not maintained 2018.3 maintenance 2018.2 not maintained 2018.1 not maintained 2017.3 not maintained 2017.2 not maintained 2017.1 not maintained","title":"Current Versions"},{"location":"#grammar-cells-migration","text":"Starting from version 2018.2.348 the MPS extensions also contain grammar cells which have been ported over from the mbeddr platform. For users of grammar cells this is mostly a transparent change since the mbeddr platform currently repackages the MPS extensions. This means that if you are using the mbeddr platform today you should not have to do much manual work.","title":"Grammar Cells Migration"},{"location":"#mbeddr-changes","text":"The most obvious change here is that the version of the mbeddr artefacts was incremented by a minor. That means you will have to adjust your build files to get the version 1.1+ instead of 1.0* . Please consult the documentation of your build tool how to configure your dependency resolving. We did this change to ensure that you do not accidentally get the new version. See the last section for the reason. The 1.0+ versions remain in our nexus as they are in the current state but will not get any updates. If you want to get newer versions of the mbeddr platform your have to change your dependency version. If you download your artefacts manually from the mbeddr Github page everything is the same as before but the version number is incremented. Other than that the artefacts didn't change and still contain the repackaged platform. We are planning to add a additional artefact that doesn't repackaged the MPS-extensions in the future to allow you more flexibility.","title":"mbeddr changes"},{"location":"#changes-to-mps-extensions","text":"In the MPS extensions we only have additive changes. We added the mpsutil.grammarcells.* modules in that same state as they were in the mbeddr platform. You shouldn't observe any changes. In addition to that we kept the language ids to avoid any visible change for existing users of the languages. The version number of the MPS extensions remain in the normal scheme as documented above.","title":"Changes to MPS Extensions"},{"location":"#required-changes-for-projects","text":"If your project is using grammar cells today it is using them through the mbeddr platform. If you do so you simply need to adjust the version number the dependency on the mbeddr platform and you are good to go. I your build scripts show errors after changing the dependency a simple \"reload modules from disk\" intention should be able to fix them. In case you currently only have dependency to the mbeddr platform because you want to use grammar cells you are now able to drop that dependency. To do so replace the dependency on the mbeddr platform with a dependency on the correct version of the MPS extensions. In this case you need to modify your MPS build scripts to no longer use the mbeddr platform as dependency but the MPS extensions. Afterwards MPS will complain that it can't find the dependency on the grammar cells languages in the build. To fix this invoke the \"reload modules from disk\" on the affected build script and the errors should go away.","title":"Required changes for projects"},{"location":"Migrating/","text":"Migrating an Extension from the mbeddr Platform There are two different kinds of migrating a extension from the mbeddr platform to the MPS-Extensions: The extension already exists as a separate plugin in the mbeddr platform The extension is currently part of the big com.mbeddr.mpsutil plugin A list of the first (easier) to migrate extension is here . Migrating extension of that list is pretty straight forward: Check the Dependencies First of all check if all dependencies are already migrated to this repository. If you not you can't migrate the extension. To do so open the com.mbeddr.build project in the mbeddr repository. Click the link in the issue that is related to the extension to select the corresponding plugin in the build script. You will see something like this: idea plugin com.mbeddr.mpsutil.jung name com.mbeddr.mpsutil.jung short (folder) name com.mbeddr.mpsutil.jung description no description version ${mbeddr.version} no vendor content: group.jung dependencies: jetbrains.mps.core ... First of all check the dependencies section of the plugin if it contains plugins that start with com.meddr then it still has dependencies and cannot be moved. Though you might want to move the plugin it depends. \ud83d\ude09 Move the Files If all dependencies are already part of the MPS-extensions we can start with migrating the extension. Follow the reference(s) in the content section. group.jung in this case: mps group group.jung solution com.mbeddr.mpsutil.jung.pluginSolution load from $mbeddr.github.core.home/code/languages/com.mbeddr.mpsutil/languages/com.mbeddr.mpsutil.jung/solutions/pluginSolution/com.mbeddr.mpsutil.jung.pluginSolution.msd language com.mbeddr.mpsutil.jung load from $mbeddr.github.core.home/code/languages/com.mbeddr.mpsutil/languages/com.mbeddr.mpsutil.jung/com.mbeddr.mpsutil.jung.mpl Both of modules in the plugin are located under the code/languages/com.mbeddr.mpsutil/languages/com.mbeddr.mpsutil.jung directory. The first thing to do is create a folder in the MPS-extensions repository where we can place these files. This folder should be placed in under the code directory of the MPS-Extensions repository. The naming convention is that it shall contain the last name of the namespace . In this case jung . All the files from the mbeddr repository code/languages/com.mbeddr.mpsutil/languages/com.mbeddr.mpsutil.jung are copied over to code/jung/lanugages in the MPS-extensions repository. The structure in the MPS-extensions repository slightly differs from the one in mbeddr. That requires an additional step. Some languages contain a dedicated solutions folder next to the language. We don't use this kind of file layout in the MPS-extensions repository. In theses cases the file from code/jung/lanugages/solutions need to get moved to code/jung/solutions . Sounds too complicated? Don't worry we will help you when sent the pull request to get it right. \ud83d\ude09 Adding the Files to the Project The files need to be part of the MPS project to show up in MPS. This is done by adding them to the project path: And then selecting the before copied files: The files end up in no folder in the project by default. They should be placed in a virtual folder of the project matches subfolder in code . In this case jung : After this is done the last step that is missing is adding the plugin to the build. Adding it to the Build To build plugin that was moved it needs to beb part of the build scripts. These scripts are located under the build folder of the project. The solution of interest is de.itemis.mps.extensions.build . And then the de.itemis.mps.extensions build project: The first thing required is a group where all the implementation modules of the plugin are places. Tests are placed in a different script. The group is named similar to the mbeddr group name but the prefix is not com.mbeddr.mpsutil but de.itemis.mps . In this case this results to de.itemis.mps.jung . This group then contains all the the solutions and languages of the plugin: After the group is created a idea plugin is required. This plugin references the group and should be placed right above the group in the build script. This is very important to keep the build script maintainable. The final step is adding the plugin to the layout section of the build project. After adding the plugin to the layout it should be possible to build the model. But in most cases a error like this will be shown: cannot build relative path to `wstx-asl-3.2.6.jar': No such path in local layout -- -- was input node: [path] BuildSourceMacroRelativePath null[8622958246116067669] in de.itemis.mps.extensions.build@5_1 -- was template node: r:54537613-52b5-40a8-b223-e87f0960b04f(jetbrains.mps.build.mps.generator.template.main@generator)/4743026300739052425 This error message means that some jar files that are used by the language or some solution are missing. The convention here is to create a lib folder in the plugin and include the required jar files. These files are usually contained in a lib folder. Sending the Pull Request To verify that everything works correctly run: ./gradlew test # mac OS / Linux gradlew.bat test # Windows This command should finish successfully. After that please create pull request at out repository and label it with migration If something doesn't work out quite well or you are unsure what to do don't worry. You can still send the PR and somebody will guide you through the process. Bonus If you are really eager you can send a PR to the mbeddr platform repository to remove the plugin there.","title":"Migrating"},{"location":"Migrating/#migrating-an-extension-from-the-mbeddr-platform","text":"There are two different kinds of migrating a extension from the mbeddr platform to the MPS-Extensions: The extension already exists as a separate plugin in the mbeddr platform The extension is currently part of the big com.mbeddr.mpsutil plugin A list of the first (easier) to migrate extension is here . Migrating extension of that list is pretty straight forward:","title":"Migrating an Extension from the mbeddr Platform"},{"location":"Migrating/#check-the-dependencies","text":"First of all check if all dependencies are already migrated to this repository. If you not you can't migrate the extension. To do so open the com.mbeddr.build project in the mbeddr repository. Click the link in the issue that is related to the extension to select the corresponding plugin in the build script. You will see something like this: idea plugin com.mbeddr.mpsutil.jung name com.mbeddr.mpsutil.jung short (folder) name com.mbeddr.mpsutil.jung description no description version ${mbeddr.version} no vendor content: group.jung dependencies: jetbrains.mps.core ... First of all check the dependencies section of the plugin if it contains plugins that start with com.meddr then it still has dependencies and cannot be moved. Though you might want to move the plugin it depends. \ud83d\ude09","title":"Check the Dependencies"},{"location":"Migrating/#move-the-files","text":"If all dependencies are already part of the MPS-extensions we can start with migrating the extension. Follow the reference(s) in the content section. group.jung in this case: mps group group.jung solution com.mbeddr.mpsutil.jung.pluginSolution load from $mbeddr.github.core.home/code/languages/com.mbeddr.mpsutil/languages/com.mbeddr.mpsutil.jung/solutions/pluginSolution/com.mbeddr.mpsutil.jung.pluginSolution.msd language com.mbeddr.mpsutil.jung load from $mbeddr.github.core.home/code/languages/com.mbeddr.mpsutil/languages/com.mbeddr.mpsutil.jung/com.mbeddr.mpsutil.jung.mpl Both of modules in the plugin are located under the code/languages/com.mbeddr.mpsutil/languages/com.mbeddr.mpsutil.jung directory. The first thing to do is create a folder in the MPS-extensions repository where we can place these files. This folder should be placed in under the code directory of the MPS-Extensions repository. The naming convention is that it shall contain the last name of the namespace . In this case jung . All the files from the mbeddr repository code/languages/com.mbeddr.mpsutil/languages/com.mbeddr.mpsutil.jung are copied over to code/jung/lanugages in the MPS-extensions repository. The structure in the MPS-extensions repository slightly differs from the one in mbeddr. That requires an additional step. Some languages contain a dedicated solutions folder next to the language. We don't use this kind of file layout in the MPS-extensions repository. In theses cases the file from code/jung/lanugages/solutions need to get moved to code/jung/solutions . Sounds too complicated? Don't worry we will help you when sent the pull request to get it right. \ud83d\ude09","title":"Move the Files"},{"location":"Migrating/#adding-the-files-to-the-project","text":"The files need to be part of the MPS project to show up in MPS. This is done by adding them to the project path: And then selecting the before copied files: The files end up in no folder in the project by default. They should be placed in a virtual folder of the project matches subfolder in code . In this case jung : After this is done the last step that is missing is adding the plugin to the build.","title":"Adding the Files to the Project"},{"location":"Migrating/#adding-it-to-the-build","text":"To build plugin that was moved it needs to beb part of the build scripts. These scripts are located under the build folder of the project. The solution of interest is de.itemis.mps.extensions.build . And then the de.itemis.mps.extensions build project: The first thing required is a group where all the implementation modules of the plugin are places. Tests are placed in a different script. The group is named similar to the mbeddr group name but the prefix is not com.mbeddr.mpsutil but de.itemis.mps . In this case this results to de.itemis.mps.jung . This group then contains all the the solutions and languages of the plugin: After the group is created a idea plugin is required. This plugin references the group and should be placed right above the group in the build script. This is very important to keep the build script maintainable. The final step is adding the plugin to the layout section of the build project. After adding the plugin to the layout it should be possible to build the model. But in most cases a error like this will be shown: cannot build relative path to `wstx-asl-3.2.6.jar': No such path in local layout -- -- was input node: [path] BuildSourceMacroRelativePath null[8622958246116067669] in de.itemis.mps.extensions.build@5_1 -- was template node: r:54537613-52b5-40a8-b223-e87f0960b04f(jetbrains.mps.build.mps.generator.template.main@generator)/4743026300739052425 This error message means that some jar files that are used by the language or some solution are missing. The convention here is to create a lib folder in the plugin and include the required jar files. These files are usually contained in a lib folder.","title":"Adding it to the Build"},{"location":"Migrating/#sending-the-pull-request","text":"To verify that everything works correctly run: ./gradlew test # mac OS / Linux gradlew.bat test # Windows This command should finish successfully. After that please create pull request at out repository and label it with migration If something doesn't work out quite well or you are unsure what to do don't worry. You can still send the PR and somebody will guide you through the process.","title":"Sending the Pull Request"},{"location":"Migrating/#bonus","text":"If you are really eager you can send a PR to the mbeddr platform repository to remove the plugin there.","title":"Bonus"},{"location":"building/","text":"Building The MPS extensions are built using gradle. In order to build the source code, all you need on the machine is a Java JDK. If you want to use the most current version of MPS-extensions (based on MPS 2019.3) JDK 11 is required for older maintenance versions you need JDK 8. Of course, if you want to hack on the MPS extensions you need MPS. The MPS version that is currently used, is in our build.gradle file under the value ext.mpsMajor. In order to build the project, run: ./gradlew # Mac and Linux gradlew.bat # Windows This will fetch the required MPS version from the internet so you need to be online when first execute the build. The default task does not run the test when building if you want to execute the tests then run: ./gradlew run_tests # Mac and Linux gradlew.bat run_tests # Windows","title":"Building"},{"location":"building/#building","text":"The MPS extensions are built using gradle. In order to build the source code, all you need on the machine is a Java JDK. If you want to use the most current version of MPS-extensions (based on MPS 2019.3) JDK 11 is required for older maintenance versions you need JDK 8. Of course, if you want to hack on the MPS extensions you need MPS. The MPS version that is currently used, is in our build.gradle file under the value ext.mpsMajor. In order to build the project, run: ./gradlew # Mac and Linux gradlew.bat # Windows This will fetch the required MPS version from the internet so you need to be online when first execute the build. The default task does not run the test when building if you want to execute the tests then run: ./gradlew run_tests # Mac and Linux gradlew.bat run_tests # Windows","title":"Building"},{"location":"contributing/","text":"Contributing Contributes are always welcome, no matter if it's additional documentation, a bugfix, a new feature to an existing extension or complete new extension that you are adding to the repository. If you are looking for an easy first contribution have a look at this list. Currently one of the biggest tasks we are working on is migrating some of the extensions from the mbeddr platform to this repository. If you like to help have a look at this page . Should you not feel comfortable to start with a code contribution additions to our documentation are always very welcome. Our documentation is in this repository as well. You can have edit it in your browser right a way if you like. For bugfixes, documentation and small new features you can open a pull request right away. Bigger features or new extensions should get some discussion in an issue just to make sure we are all on the same page about what is going to be done. If you are unsure what to do don't hesitate to open a issue and ask for help.","title":"Contributing"},{"location":"contributing/#contributing","text":"Contributes are always welcome, no matter if it's additional documentation, a bugfix, a new feature to an existing extension or complete new extension that you are adding to the repository. If you are looking for an easy first contribution have a look at this list. Currently one of the biggest tasks we are working on is migrating some of the extensions from the mbeddr platform to this repository. If you like to help have a look at this page . Should you not feel comfortable to start with a code contribution additions to our documentation are always very welcome. Our documentation is in this repository as well. You can have edit it in your browser right a way if you like. For bugfixes, documentation and small new features you can open a pull request right away. Bigger features or new extensions should get some discussion in an issue just to make sure we are all on the same page about what is going to be done. If you are unsure what to do don't hesitate to open a issue and ask for help.","title":"Contributing"},{"location":"extensions/diagrams/","text":"Diagrams Language Namespace : de.itemis.mps.editor.diagram If you have downloaded the recent mbeddr master branch, you will have noticed that, for example, component wiring and state machines can now be edited graphically. The screenshots below show examples of these two notations. This screenshot shows a few interesting features: you can embed diagrams anywhere in \"text\", you can use different shapes (at this point drawn by custom Java code), you can use various line styles, the framework supports ports (i.e., connection endpoints on the boxes), inside boxes you can use arbitrary MPS text (or other) editors, and the system also supports edge and endpoint labels. Port labels are also supported, but they are only shown if the mouse is \"in the vicinity\" of the port to not clutter the diagram. Below is a second screenshot of a bigger diagram: This one illustrates that the approach scales to reasonable sizes, shows that zooming is supported and also demonstrates the auto layouting capability. The graphical notation also integrates with things such as tooltips. Below is another example diagram that shows a different language: The definition of a graphical editor is based on the same \"cell\" abstraction used in other MPS editors: the language for defining editors contains additional cells that are then rendered as a diagram (diagram, diagram.box, diagram.edge). Similar to tables, these abstractions for defining graphical editors rely on queries to make sure that the structure of the graphical editor does not have to directly correspond to the structure of the AST (for example, in terms of ownership). The language also supports hierarchical diagrams, for example, in state machines. To see example code, check out InstanceConfiguration and Statemachine. The diagram notation is relatively sophisticated and requires much more documentation than what we can provide right now on this page. More will follow later.","title":"Diagrams"},{"location":"extensions/diagrams/#diagrams","text":"Language Namespace : de.itemis.mps.editor.diagram If you have downloaded the recent mbeddr master branch, you will have noticed that, for example, component wiring and state machines can now be edited graphically. The screenshots below show examples of these two notations. This screenshot shows a few interesting features: you can embed diagrams anywhere in \"text\", you can use different shapes (at this point drawn by custom Java code), you can use various line styles, the framework supports ports (i.e., connection endpoints on the boxes), inside boxes you can use arbitrary MPS text (or other) editors, and the system also supports edge and endpoint labels. Port labels are also supported, but they are only shown if the mouse is \"in the vicinity\" of the port to not clutter the diagram. Below is a second screenshot of a bigger diagram: This one illustrates that the approach scales to reasonable sizes, shows that zooming is supported and also demonstrates the auto layouting capability. The graphical notation also integrates with things such as tooltips. Below is another example diagram that shows a different language: The definition of a graphical editor is based on the same \"cell\" abstraction used in other MPS editors: the language for defining editors contains additional cells that are then rendered as a diagram (diagram, diagram.box, diagram.edge). Similar to tables, these abstractions for defining graphical editors rely on queries to make sure that the structure of the graphical editor does not have to directly correspond to the structure of the AST (for example, in terms of ownership). The language also supports hierarchical diagrams, for example, in state machines. To see example code, check out InstanceConfiguration and Statemachine. The diagram notation is relatively sophisticated and requires much more documentation than what we can provide right now on this page. More will follow later.","title":"Diagrams"},{"location":"extensions/node-versioning/","text":"Node Versioning Language Namespace : de.itemis.mps.nodeversioning The node versioning extension gives support for storing different states/versions of a node inside of the model. It is not a replacement for version control systems like git . An example use case might be a model is used to describe an API and the users wants to detect changes between different releases of the API. This API has a version number that follows semVer associated with it. Now when users wants check what changes happened since the last release the information stored by this extension can be used to diff the current state against the last released one. The scope of this extension is to provide a way to store the versions of a node and do change detection. It does intentionally not provide ways how to semantically reason about a change as this is highly domain specific. It might be used in conjunction with the nodecomparator to do structural diffs between versions. State: Incubating This extension is currently incubating and might under go substantial changes in the future. Currently it only supports storing of the version information and change detection. For future feature ideas see the potential features section. What is a Node When we speak of a node in this document we mean the node and all of its children but not of the referenced nodes. Sometimes this is also called subtree . When we speak of the dependencies of a node we mean all nodes that are referenced by either node itself or it children. Meta Model The version information is stored on the node that is versioned as a NodeAttribute called NodeVersion . The NodeVersion contains a copy of the node at point in time when the version was created. In addition to the copy it also stores a VersionNumber which is a simple integer incremented with each version that is created. The VersionNumber has no other semantics than to provide ordering to the versions. To be able to detect changes of a node it also stores a hash of the node. The NodeVersion also contains a list of all the dependencies (reference targets) of the node and its version, these are called LinkVersion . Change Detection On first glance change detection looks pretty straight forward. A node has changed when either the node itself has changed or one of the dependencies: But if we at MPS models they are not simple tree but graphs that allow reference cycles. In this cases we cannot simply traverse the complete graph over the edges since we would end up in a cycle. Imagine model like this: In this case the change detection has to take into account that there is a cycle from 5 -- 4 -- 6 -- 5 . The change detection algorithm detects this cycle and handles them appropriately. If none of the participants in a cycle have local changes then the whole cycle is assumed to be unchanged. Technically the detection if a node has changed since the last time it has been versioned is done via hashing. If the hash differs from the hash calculated for the last version then the node has changed. The current implementation uses SHA 1 hashes to verify if the node has changed. Potential Features time travel : Getting the model back into the exact same state as it was when a specific version on a node was created. Most likely as some kind of transient model that is not visible to the user. Referencing nodes in a specific version. While this to some degree already happens behind the scenes. It might be useful for the user to implement an API in specific version. Delete handling. At the moment when the user deletes a node that is still referenced from some other node in an older version (that is potentially not visible to the user) the model is in a broken state. Usage The general pattern that all functionally of the nodeversioning extension that all parts follow is that it will never mutate the model during its execution. It will collect changes or calculate a new set of NodeVersions but its up to the user of the extension to actually mutate the model. This behaviour is due to the fact that the domain requires human interaction to review the changes and allow to veto based on that review. First of all models that should get versioned need to use the de.itemis.mps.nodeversioning language. Most probably you want to expose this to the end user through a DevKit. This language does not add anything the user can see or interact with but adds the NodeAttribute s required for the versioning. In order to version a model or otherwise interact with the versions stored in the nodes use the de.itemis.mps.nodeversioning.runtime solution. The class you want to have a look at is VersioningHelper it provides the methods to version a node or check if something has changed. For more details see the JavaDoc on that class.","title":"Node Versioning"},{"location":"extensions/node-versioning/#node-versioning","text":"Language Namespace : de.itemis.mps.nodeversioning The node versioning extension gives support for storing different states/versions of a node inside of the model. It is not a replacement for version control systems like git . An example use case might be a model is used to describe an API and the users wants to detect changes between different releases of the API. This API has a version number that follows semVer associated with it. Now when users wants check what changes happened since the last release the information stored by this extension can be used to diff the current state against the last released one. The scope of this extension is to provide a way to store the versions of a node and do change detection. It does intentionally not provide ways how to semantically reason about a change as this is highly domain specific. It might be used in conjunction with the nodecomparator to do structural diffs between versions. State: Incubating This extension is currently incubating and might under go substantial changes in the future. Currently it only supports storing of the version information and change detection. For future feature ideas see the potential features section.","title":"Node Versioning"},{"location":"extensions/node-versioning/#what-is-a-node","text":"When we speak of a node in this document we mean the node and all of its children but not of the referenced nodes. Sometimes this is also called subtree . When we speak of the dependencies of a node we mean all nodes that are referenced by either node itself or it children.","title":"What is a Node"},{"location":"extensions/node-versioning/#meta-model","text":"The version information is stored on the node that is versioned as a NodeAttribute called NodeVersion . The NodeVersion contains a copy of the node at point in time when the version was created. In addition to the copy it also stores a VersionNumber which is a simple integer incremented with each version that is created. The VersionNumber has no other semantics than to provide ordering to the versions. To be able to detect changes of a node it also stores a hash of the node. The NodeVersion also contains a list of all the dependencies (reference targets) of the node and its version, these are called LinkVersion .","title":"Meta Model"},{"location":"extensions/node-versioning/#change-detection","text":"On first glance change detection looks pretty straight forward. A node has changed when either the node itself has changed or one of the dependencies: But if we at MPS models they are not simple tree but graphs that allow reference cycles. In this cases we cannot simply traverse the complete graph over the edges since we would end up in a cycle. Imagine model like this: In this case the change detection has to take into account that there is a cycle from 5 -- 4 -- 6 -- 5 . The change detection algorithm detects this cycle and handles them appropriately. If none of the participants in a cycle have local changes then the whole cycle is assumed to be unchanged. Technically the detection if a node has changed since the last time it has been versioned is done via hashing. If the hash differs from the hash calculated for the last version then the node has changed. The current implementation uses SHA 1 hashes to verify if the node has changed.","title":"Change Detection"},{"location":"extensions/node-versioning/#potential-features","text":"time travel : Getting the model back into the exact same state as it was when a specific version on a node was created. Most likely as some kind of transient model that is not visible to the user. Referencing nodes in a specific version. While this to some degree already happens behind the scenes. It might be useful for the user to implement an API in specific version. Delete handling. At the moment when the user deletes a node that is still referenced from some other node in an older version (that is potentially not visible to the user) the model is in a broken state.","title":"Potential Features"},{"location":"extensions/node-versioning/#usage","text":"The general pattern that all functionally of the nodeversioning extension that all parts follow is that it will never mutate the model during its execution. It will collect changes or calculate a new set of NodeVersions but its up to the user of the extension to actually mutate the model. This behaviour is due to the fact that the domain requires human interaction to review the changes and allow to veto based on that review. First of all models that should get versioned need to use the de.itemis.mps.nodeversioning language. Most probably you want to expose this to the end user through a DevKit. This language does not add anything the user can see or interact with but adds the NodeAttribute s required for the versioning. In order to version a model or otherwise interact with the versions stored in the nodes use the de.itemis.mps.nodeversioning.runtime solution. The class you want to have a look at is VersioningHelper it provides the methods to version a node or check if something has changed. For more details see the JavaDoc on that class.","title":"Usage"},{"location":"extensions/plaintext-gen/","text":"JetBrains MPS Text Generator Plugin This extension is an alternative text generator for MPS, using the standard model to model generation mechanisms (node macros, loop macros, property macros, etc.) to generate plain text, as opposed to MPS's programmatical textgens. It allows you to: * generate directly to plain text without modeling your generation target language * generate to multiple text formats in the same generator run * create multiple textgens that obey generator priority rules The plugin also enables copy/pasting an existing piece of text and parameterizing parts of this text using macros. For fine-grained control of whitespaces and indent-characters, the plaintextflow extension is available. It can be imported as a separate language (extending the plaintextgen language), so it doesn't disrupt existing plaintextgen functionality. Quickstart The quickest way to install the plaintextgen plugin is to add it from the JetBrains plugins repository: * in MPS, select File - Settings - Plugins - Browse repositories... * search for plaintextgen * press Install After installation, add com.dslfoundry.plaintextgen to the Used Languages of your generator ( main@generator model) and create a TextgenText template in your generator. For examples, see the test language in this repository. Presentations and tutorials A tutorial on plaintextgen is available on the DSLFoundry blog . A presentation that was held at the 27 February 2019 meeting of MPS Power Users Group can be found at the DSLFoundry MPS-teaching repository . Main features Group and layout your content using horizontal, vertical, and indented collections Split plain text into various cells to apply MPS generator macros to them Paste unstructured text from a buffer to MPS. The structure of this text (indentations, new lines, tabs) will be automatically analyzed and converted into a TextgenText structure which you can then parameterize at your convenience. Advantages of this plugin over the default textgen In short, this plugin brings MPS - plaintext connectivity in a pretty usable way to MPS. Text generation can be part of your normal generator chain and can thus have a place in the generator priorities The language looks similar to the MPS editor language, which helps you to structure/layout your text, including indentation Different use cases are accomodated: Pasting in larger amounts of text from the clipboard and parametrizing some of it Making text from scratch and parameterizing some of it Differences with standard textgen mechanism The standard textgen approach assumes that you model your target language (e.g. XML, or C in mbeddr) as an MPS language with all its concepts. Concept textgens provide a simple translation from concept to text. This approach is great for language extensibility, but requires that you model concepts of your target language, which in some cases is too large an investment. This plugin allows you to to write a text template and fill in the gaps using standard macros. For example: You generate from your DSL directly to VHDL, but VHDL has not yet been modeled in MPS. Additionally, because text is now also an MPS model, all standard generator mechanisms (including reductions and generator priorities) apply. This is not the case for the default textgens, which are only triggered after all model to model transformations are complete. Also, this approach enables you to implement the textgen as a language extension (and therefore define multiple textgens for the same concept).","title":"Plaintext Generator"},{"location":"extensions/plaintext-gen/#jetbrains-mps-text-generator-plugin","text":"This extension is an alternative text generator for MPS, using the standard model to model generation mechanisms (node macros, loop macros, property macros, etc.) to generate plain text, as opposed to MPS's programmatical textgens. It allows you to: * generate directly to plain text without modeling your generation target language * generate to multiple text formats in the same generator run * create multiple textgens that obey generator priority rules The plugin also enables copy/pasting an existing piece of text and parameterizing parts of this text using macros. For fine-grained control of whitespaces and indent-characters, the plaintextflow extension is available. It can be imported as a separate language (extending the plaintextgen language), so it doesn't disrupt existing plaintextgen functionality.","title":"JetBrains MPS Text Generator Plugin"},{"location":"extensions/plaintext-gen/#quickstart","text":"The quickest way to install the plaintextgen plugin is to add it from the JetBrains plugins repository: * in MPS, select File - Settings - Plugins - Browse repositories... * search for plaintextgen * press Install After installation, add com.dslfoundry.plaintextgen to the Used Languages of your generator ( main@generator model) and create a TextgenText template in your generator. For examples, see the test language in this repository.","title":"Quickstart"},{"location":"extensions/plaintext-gen/#presentations-and-tutorials","text":"A tutorial on plaintextgen is available on the DSLFoundry blog . A presentation that was held at the 27 February 2019 meeting of MPS Power Users Group can be found at the DSLFoundry MPS-teaching repository .","title":"Presentations and tutorials"},{"location":"extensions/plaintext-gen/#main-features","text":"Group and layout your content using horizontal, vertical, and indented collections Split plain text into various cells to apply MPS generator macros to them Paste unstructured text from a buffer to MPS. The structure of this text (indentations, new lines, tabs) will be automatically analyzed and converted into a TextgenText structure which you can then parameterize at your convenience.","title":"Main features"},{"location":"extensions/plaintext-gen/#advantages-of-this-plugin-over-the-default-textgen","text":"In short, this plugin brings MPS - plaintext connectivity in a pretty usable way to MPS. Text generation can be part of your normal generator chain and can thus have a place in the generator priorities The language looks similar to the MPS editor language, which helps you to structure/layout your text, including indentation Different use cases are accomodated: Pasting in larger amounts of text from the clipboard and parametrizing some of it Making text from scratch and parameterizing some of it","title":"Advantages of this plugin over the default textgen"},{"location":"extensions/plaintext-gen/#differences-with-standard-textgen-mechanism","text":"The standard textgen approach assumes that you model your target language (e.g. XML, or C in mbeddr) as an MPS language with all its concepts. Concept textgens provide a simple translation from concept to text. This approach is great for language extensibility, but requires that you model concepts of your target language, which in some cases is too large an investment. This plugin allows you to to write a text template and fill in the gaps using standard macros. For example: You generate from your DSL directly to VHDL, but VHDL has not yet been modeled in MPS. Additionally, because text is now also an MPS model, all standard generator mechanisms (including reductions and generator priorities) apply. This is not the case for the default textgens, which are only triggered after all model to model transformations are complete. Also, this approach enables you to implement the textgen as a language extension (and therefore define multiple textgens for the same concept).","title":"Differences with standard textgen mechanism"},{"location":"extensions/shadowmodels/","text":"Shadow Models A shadow model is a non-editable model derived from existing models by model-to-model transformations. It is incrementally maintained while editing the input model. Transformations are described in a special language designed to support incremental updates of the output model. Dynamic dependency tracking is used during the executing of the transformations which removes the need for a declarative language. BaseLanguage expressions with all its extensions are supported inside the transformation rules. Download Download the nightly build of the plugins from the release page . Examples There is a separate Shadow Models (Examples) plugin that contains some example languages and transformation implementations to show you how to build your own shadow models. The languages and input models can be found in the namespace de.q60.mps.shadowmodels.examples . The transformations are implemented in the transformation aspect. Transformations The transformation language is similar to the MPS generator language. It has transformation rules with a left side that describes the input it applies to and a right side that creates the output. The right side is similar to light quotations instead of using the concrete syntax of the target language. Repository Meta Model When you implement transformations there is an important difference when working with modules and models. In the world of shadow models there is only one root node concept Repository . Modules and models are descendants of this single root node. What in MPS is a root node is here just a child of a node of concept Model . When you ask a root node for its parent you will get the Model node. This has the advantage that you can define transformations on modules and models in the same way as on any other node. You can query them using the more convenient smodel language instead of the Java API. You have to keep in mind that asking a node for its root node will always return the repository. If you need to know the model of a node you have to write node.ancestor Model instead. node.getModel() will always return null. You can find the whole meta model in the language de.q60.mps.shadowmodels.runtimelang . Here is a summary of it: Repository modules: Module[0..n] Module implements INamedConcept id: string models: Model[0..n] Model implements INamedConcept rootNodes: BaseConcept[0..n] Shadow Repository You can make the output of your transformations appear in the project explorer as shown in the image below. By default this is disabled. You can activate it by choosing Tools Activate Shadow Repository in the main menu. To add your own output you have to define a transformation that contributes to the predefined transformation ShadowRepository.Repository in the transformations aspect of the language de.q60.mps.shadowmodels.repository . Here is an example that you can find in the language de.q60.mps.shadowmodels.examples.statemachine : transformation t1 contributes to ShadowRepository.Repository (i0: Repository) - o0: Repository { modules: Module { name: examples.statemachines models: map _.modules.models.where(...) - call outputModel _ } } It is important to know that the whole shadow repository is executed inside a fork. This will make sure that references are updated to point to nodes inside the shadow repository. You can of course create additional sub forks. Forks Shadow models allows you to write transformations in two different styles. You can write them like functions and call everything explicitly or you can use forks. Forks basically allow you to write transformation similar to how you would do it in the MPS generator. In MPS the unit of transformation is a model. You cannot generate a single class (in case of baseLanguage code) inside a model and you cannot generate classes from different models together. Shadow model forks can have any node as the root of the fork. If you decide to make a model the root of your fork, then you have the equivalent to MPS. But often the single root nodes inside the model are a better choice for the fork root. In case of baseLanguage classes there is no difference if two classes are in the same or in different models. Forks also have support for mapping labels as you know them from MPS. They can only work if the map is filled before mappings are queried from them. Forks execute all transformations (which fills the map) before any reference is resolved (which queries mapping). As in MPS where mapping labels only work inside the same model, here they only work inside the same fork. Luckily, both have a solution for that. MPS introduced cross model generation where you define special checkpoints inside the generation plan. In shadow models you can define fork dependencies . If a transformation or mapping cannot be found in the same fork, they are searched in all forks that are defined as a dependency. You can add dependencies in the upper part of any transformation that is part of the fork. As all transformations, forks are executed on demand. You don't have to take care of generating your models in the correct order. If you define a fork dependency, the transformation engine will make sure that the target fork exists when it's needed. A fork can specify a list of transformations that are automatically applied to the input, just like reduction rules in MPS. By default there is only one attempt to apply transformations on all nodes that you copy using the transform keyword. If there are nodes in the output where one of the transformations would again be applicable, nothing will happen unless you enable the fixpoint mode. Then the fork is applied again on the output of the previous execution. For performance reasons a fork is by default not in fixpoint mode. The identity of a fork is composed of the fork name and the parameter values of the fork call. You can use this to create multiple copies of the same input node. Just add an additional (string) parameter to the fork and use a different value for each copy. The fork identity is part of the node identity of all its output nodes. Reference Resolution Differences for Forks All transformations inside a fork are executed before any reference resolution happens. You will get an exception when the reference target was not created in this first phase. If you are not inside a fork, there aren't these two phases. Transformations are executed independent of whether you access it through a parent-child relation or a reference. You won't get an exception in this case. Identity of a Node A node in the output is identified by the transformation name and the parameter values of the transformation call. If you call a fork then the identity of the fork (fork name + parameter values) will be part of all it's output nodes. For references it's often enough to specify the transformation call that creates the target. It will then be resolved in the same fork, its dependencies or the parent fork. If you need to, you can also specify the exact fork of the reference target. References to Non-Shadow Nodes If you want to generate code against an existing runtime library, you can just write a baseLanguage expression that returns an SNode or SNodeReference to set a reference to a fixed target. No resolution will happen in this case. In the statemachines example you can find the following transformation: transformation enumConst overrides ... [i0: INamedConcept] - o0: EnumConstantDeclaration { name: _.name constructor - *[node-ptr/Object- Object/] } The constructor reference is pointing to the constructor of the Object class in the JDK stub models. Traceback For debugging the output in the shadow repository you show the transformations that produced a given output node. Right click on an output node and choose Language Debug Shadow Models: Traceback from the context menu. Reduction rules and generation plans There are some use cases that are easier to implement with the MPS generator language than with the explicit transformation calls of the shadow models language. That's why there are now similar abstraction in the shadow models language. Mappings Cnfigurations and Goals A mapping configuration in MPS is a container for reduction/weaving/... rules. You can define rules to specify the order in which the mappings configuration are applied on the input model. In shadow models there is now also a \"mapping configuration\" concept. You can specify reduction and weaving rules inside of it. The following example shows a concept that doesn't exist in MPS: goals. goal toJava mapping configuration mc1 { goal: toJava } A goal specifies what should happen with the input model. All mapping configurations that contribute to the same goal are applied when the goal is called on some input. While in MPS you always execute the same generators on a model, goals enable you to produce multiple outputs by executing different goals on the same input. Generation plans When you invoke a goal all mapping configurations that contribute to that goal are collected and sorted into a generation plan. A generation plan is dynamically computed from a set of rules. The rules are the same as known from MPS. A before/after rule will separate the generation into two steps where the output of the first is the input of the second one. goal toJava mapping configuration mc1 { ... } mapping configuration mc2 { ... } genplan rule: mc1 before mc3 Reduction Rules Reduction rules are automatically applied on any applicable node on the input including its descendants. Rules are repeatedly applied on the output up to 10 times. If rules are then still applicable, the generation fails. Conflicting reduction rules don't cause the generation to fail. They behave in the same way as in the MPS generator. The first applicable rule is used. If they are part of the same mapping configuration the order of the rules is relevant. If they are part of different mappings configurations it is undefined which rule is used. Weaving Rules Weaving rules are used to insert an additional node as a child to an output node. The target node is specified in the same way are in in references, but it has to be part of the output of the current goal execution. Weaving rules are applied only on the initial input or on output nodes of a transformation. If a node was copied without any change between substeps, weaving rules are not applied. This prevents them from being reapplied on the same node again and again. Property Rules Property rules can change a value without doing any structural change to the model. They are applied on the output after executing reduction and weaving rules. Reference Rules Reference rules are the same as property rules except that they change a reference target instead of a property value. The target is resolved in the scope of the output node. Scopes Scopes can be used to resolve conflicts during reference resolution. If the same node is copied multiple times into the output and you want to reference one of them, you can put the source and the target node into the same scope.","title":"Shadow Models"},{"location":"extensions/shadowmodels/#shadow-models","text":"A shadow model is a non-editable model derived from existing models by model-to-model transformations. It is incrementally maintained while editing the input model. Transformations are described in a special language designed to support incremental updates of the output model. Dynamic dependency tracking is used during the executing of the transformations which removes the need for a declarative language. BaseLanguage expressions with all its extensions are supported inside the transformation rules.","title":"Shadow Models"},{"location":"extensions/shadowmodels/#download","text":"Download the nightly build of the plugins from the release page .","title":"Download"},{"location":"extensions/shadowmodels/#examples","text":"There is a separate Shadow Models (Examples) plugin that contains some example languages and transformation implementations to show you how to build your own shadow models. The languages and input models can be found in the namespace de.q60.mps.shadowmodels.examples . The transformations are implemented in the transformation aspect.","title":"Examples"},{"location":"extensions/shadowmodels/#transformations","text":"The transformation language is similar to the MPS generator language. It has transformation rules with a left side that describes the input it applies to and a right side that creates the output. The right side is similar to light quotations instead of using the concrete syntax of the target language.","title":"Transformations"},{"location":"extensions/shadowmodels/#repository-meta-model","text":"When you implement transformations there is an important difference when working with modules and models. In the world of shadow models there is only one root node concept Repository . Modules and models are descendants of this single root node. What in MPS is a root node is here just a child of a node of concept Model . When you ask a root node for its parent you will get the Model node. This has the advantage that you can define transformations on modules and models in the same way as on any other node. You can query them using the more convenient smodel language instead of the Java API. You have to keep in mind that asking a node for its root node will always return the repository. If you need to know the model of a node you have to write node.ancestor Model instead. node.getModel() will always return null. You can find the whole meta model in the language de.q60.mps.shadowmodels.runtimelang . Here is a summary of it: Repository modules: Module[0..n] Module implements INamedConcept id: string models: Model[0..n] Model implements INamedConcept rootNodes: BaseConcept[0..n]","title":"Repository Meta Model"},{"location":"extensions/shadowmodels/#shadow-repository","text":"You can make the output of your transformations appear in the project explorer as shown in the image below. By default this is disabled. You can activate it by choosing Tools Activate Shadow Repository in the main menu. To add your own output you have to define a transformation that contributes to the predefined transformation ShadowRepository.Repository in the transformations aspect of the language de.q60.mps.shadowmodels.repository . Here is an example that you can find in the language de.q60.mps.shadowmodels.examples.statemachine : transformation t1 contributes to ShadowRepository.Repository (i0: Repository) - o0: Repository { modules: Module { name: examples.statemachines models: map _.modules.models.where(...) - call outputModel _ } } It is important to know that the whole shadow repository is executed inside a fork. This will make sure that references are updated to point to nodes inside the shadow repository. You can of course create additional sub forks.","title":"Shadow Repository"},{"location":"extensions/shadowmodels/#forks","text":"Shadow models allows you to write transformations in two different styles. You can write them like functions and call everything explicitly or you can use forks. Forks basically allow you to write transformation similar to how you would do it in the MPS generator. In MPS the unit of transformation is a model. You cannot generate a single class (in case of baseLanguage code) inside a model and you cannot generate classes from different models together. Shadow model forks can have any node as the root of the fork. If you decide to make a model the root of your fork, then you have the equivalent to MPS. But often the single root nodes inside the model are a better choice for the fork root. In case of baseLanguage classes there is no difference if two classes are in the same or in different models. Forks also have support for mapping labels as you know them from MPS. They can only work if the map is filled before mappings are queried from them. Forks execute all transformations (which fills the map) before any reference is resolved (which queries mapping). As in MPS where mapping labels only work inside the same model, here they only work inside the same fork. Luckily, both have a solution for that. MPS introduced cross model generation where you define special checkpoints inside the generation plan. In shadow models you can define fork dependencies . If a transformation or mapping cannot be found in the same fork, they are searched in all forks that are defined as a dependency. You can add dependencies in the upper part of any transformation that is part of the fork. As all transformations, forks are executed on demand. You don't have to take care of generating your models in the correct order. If you define a fork dependency, the transformation engine will make sure that the target fork exists when it's needed. A fork can specify a list of transformations that are automatically applied to the input, just like reduction rules in MPS. By default there is only one attempt to apply transformations on all nodes that you copy using the transform keyword. If there are nodes in the output where one of the transformations would again be applicable, nothing will happen unless you enable the fixpoint mode. Then the fork is applied again on the output of the previous execution. For performance reasons a fork is by default not in fixpoint mode. The identity of a fork is composed of the fork name and the parameter values of the fork call. You can use this to create multiple copies of the same input node. Just add an additional (string) parameter to the fork and use a different value for each copy. The fork identity is part of the node identity of all its output nodes.","title":"Forks"},{"location":"extensions/shadowmodels/#reference-resolution","text":"","title":"Reference Resolution"},{"location":"extensions/shadowmodels/#differences-for-forks","text":"All transformations inside a fork are executed before any reference resolution happens. You will get an exception when the reference target was not created in this first phase. If you are not inside a fork, there aren't these two phases. Transformations are executed independent of whether you access it through a parent-child relation or a reference. You won't get an exception in this case.","title":"Differences for Forks"},{"location":"extensions/shadowmodels/#identity-of-a-node","text":"A node in the output is identified by the transformation name and the parameter values of the transformation call. If you call a fork then the identity of the fork (fork name + parameter values) will be part of all it's output nodes. For references it's often enough to specify the transformation call that creates the target. It will then be resolved in the same fork, its dependencies or the parent fork. If you need to, you can also specify the exact fork of the reference target.","title":"Identity of a Node"},{"location":"extensions/shadowmodels/#references-to-non-shadow-nodes","text":"If you want to generate code against an existing runtime library, you can just write a baseLanguage expression that returns an SNode or SNodeReference to set a reference to a fixed target. No resolution will happen in this case. In the statemachines example you can find the following transformation: transformation enumConst overrides ... [i0: INamedConcept] - o0: EnumConstantDeclaration { name: _.name constructor - *[node-ptr/Object- Object/] } The constructor reference is pointing to the constructor of the Object class in the JDK stub models.","title":"References to Non-Shadow Nodes"},{"location":"extensions/shadowmodels/#traceback","text":"For debugging the output in the shadow repository you show the transformations that produced a given output node. Right click on an output node and choose Language Debug Shadow Models: Traceback from the context menu.","title":"Traceback"},{"location":"extensions/shadowmodels/#reduction-rules-and-generation-plans","text":"There are some use cases that are easier to implement with the MPS generator language than with the explicit transformation calls of the shadow models language. That's why there are now similar abstraction in the shadow models language.","title":"Reduction rules and generation plans"},{"location":"extensions/shadowmodels/#mappings-cnfigurations-and-goals","text":"A mapping configuration in MPS is a container for reduction/weaving/... rules. You can define rules to specify the order in which the mappings configuration are applied on the input model. In shadow models there is now also a \"mapping configuration\" concept. You can specify reduction and weaving rules inside of it. The following example shows a concept that doesn't exist in MPS: goals. goal toJava mapping configuration mc1 { goal: toJava } A goal specifies what should happen with the input model. All mapping configurations that contribute to the same goal are applied when the goal is called on some input. While in MPS you always execute the same generators on a model, goals enable you to produce multiple outputs by executing different goals on the same input.","title":"Mappings Cnfigurations and Goals"},{"location":"extensions/shadowmodels/#generation-plans","text":"When you invoke a goal all mapping configurations that contribute to that goal are collected and sorted into a generation plan. A generation plan is dynamically computed from a set of rules. The rules are the same as known from MPS. A before/after rule will separate the generation into two steps where the output of the first is the input of the second one. goal toJava mapping configuration mc1 { ... } mapping configuration mc2 { ... } genplan rule: mc1 before mc3","title":"Generation plans"},{"location":"extensions/shadowmodels/#reduction-rules","text":"Reduction rules are automatically applied on any applicable node on the input including its descendants. Rules are repeatedly applied on the output up to 10 times. If rules are then still applicable, the generation fails. Conflicting reduction rules don't cause the generation to fail. They behave in the same way as in the MPS generator. The first applicable rule is used. If they are part of the same mapping configuration the order of the rules is relevant. If they are part of different mappings configurations it is undefined which rule is used.","title":"Reduction Rules"},{"location":"extensions/shadowmodels/#weaving-rules","text":"Weaving rules are used to insert an additional node as a child to an output node. The target node is specified in the same way are in in references, but it has to be part of the output of the current goal execution. Weaving rules are applied only on the initial input or on output nodes of a transformation. If a node was copied without any change between substeps, weaving rules are not applied. This prevents them from being reapplied on the same node again and again.","title":"Weaving Rules"},{"location":"extensions/shadowmodels/#property-rules","text":"Property rules can change a value without doing any structural change to the model. They are applied on the output after executing reduction and weaving rules.","title":"Property Rules"},{"location":"extensions/shadowmodels/#reference-rules","text":"Reference rules are the same as property rules except that they change a reference target instead of a property value. The target is resolved in the scope of the output node.","title":"Reference Rules"},{"location":"extensions/shadowmodels/#scopes","text":"Scopes can be used to resolve conflicts during reference resolution. If the same node is copied multiple times into the output and you want to reference one of them, you can put the source and the target node into the same scope.","title":"Scopes"}]}